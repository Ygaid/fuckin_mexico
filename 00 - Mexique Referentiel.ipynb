{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b22f50da-d37e-48d0-8715-d0b8ce6f6dd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Librairie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "209f2fc9-87e9-4ada-bdc1-f543ea3f4e89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: pydantic in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (2.10.6)\nRequirement already satisfied: openpyxl in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (3.1.5)\nRequirement already satisfied: pydantic-core==2.27.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from pydantic) (2.27.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from pydantic) (0.7.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from pydantic) (4.12.2)\nRequirement already satisfied: et-xmlfile in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: pypdf in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: typing_extensions>=4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from pypdf) (4.12.2)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: pdf2image in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (1.17.0)\nRequirement already satisfied: Pillow in /databricks/python3/lib/python3.10/site-packages (9.4.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: pdfplumber in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (0.11.5)\nRequirement already satisfied: Pillow>=9.1 in /databricks/python3/lib/python3.10/site-packages (from pdfplumber) (9.4.0)\nRequirement already satisfied: pdfminer.six==20231228 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from pdfplumber) (20231228)\nRequirement already satisfied: pypdfium2>=4.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from pdfplumber) (4.30.1)\nRequirement already satisfied: cryptography>=36.0.0 in /databricks/python3/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (39.0.1)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (2.0.4)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.15.1)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (4.67.1)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: unstructured in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (0.16.15)\nRequirement already satisfied: beautifulsoup4 in /databricks/python3/lib/python3.10/site-packages (from unstructured) (4.11.1)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.10/site-packages (from unstructured) (5.9.0)\nRequirement already satisfied: nltk in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (3.9.1)\nRequirement already satisfied: backoff in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (2.2.1)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (4.67.1)\nRequirement already satisfied: chardet in /databricks/python3/lib/python3.10/site-packages (from unstructured) (4.0.0)\nRequirement already satisfied: dataclasses-json in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (0.6.7)\nRequirement already satisfied: python-oxmsg in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (0.0.1)\nRequirement already satisfied: rapidfuzz in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (3.11.0)\nRequirement already satisfied: wrapt in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (1.17.2)\nRequirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (4.12.2)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from unstructured) (2.28.1)\nRequirement already satisfied: filetype in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (1.2.0)\nRequirement already satisfied: ndjson in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (0.3.1)\nRequirement already satisfied: python-magic in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (0.4.27)\nRequirement already satisfied: unstructured-client in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (0.29.0)\nRequirement already satisfied: langdetect in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (1.0.9)\nRequirement already satisfied: python-iso639 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (2025.1.27)\nRequirement already satisfied: lxml in /databricks/python3/lib/python3.10/site-packages (from unstructured) (4.9.1)\nRequirement already satisfied: emoji in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (2.14.1)\nRequirement already satisfied: html5lib in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured) (1.1)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.10/site-packages (from unstructured) (1.23.5)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.3.2.post1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from dataclasses-json->unstructured) (0.9.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.26.0)\nRequirement already satisfied: six>=1.9 in /usr/lib/python3/dist-packages (from html5lib->unstructured) (1.16.0)\nRequirement already satisfied: webencodings in /databricks/python3/lib/python3.10/site-packages (from html5lib->unstructured) (0.5.1)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk->unstructured) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from nltk->unstructured) (2024.11.6)\nRequirement already satisfied: click in /databricks/python3/lib/python3.10/site-packages (from nltk->unstructured) (8.0.4)\nRequirement already satisfied: olefile in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from python-oxmsg->unstructured) (0.47)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->unstructured) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->unstructured) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->unstructured) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->unstructured) (3.4)\nRequirement already satisfied: pydantic<2.11.0,>=2.10.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured-client->unstructured) (2.10.6)\nRequirement already satisfied: cryptography>=3.1 in /databricks/python3/lib/python3.10/site-packages (from unstructured-client->unstructured) (39.0.1)\nRequirement already satisfied: pypdf>=4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured-client->unstructured) (5.2.0)\nRequirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.6)\nRequirement already satisfied: nest-asyncio>=1.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.6.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /databricks/python3/lib/python3.10/site-packages (from unstructured-client->unstructured) (2.8.2)\nRequirement already satisfied: aiofiles>=24.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured-client->unstructured) (24.1.0)\nRequirement already satisfied: requests-toolbelt>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.0)\nRequirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured-client->unstructured) (0.2.2)\nRequirement already satisfied: httpx>=0.27.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from unstructured-client->unstructured) (0.28.1)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.10/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.15.1)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.5.0)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.2)\nRequirement already satisfied: pydantic-core==2.27.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from pydantic<2.11.0,>=2.10.3->unstructured-client->unstructured) (2.27.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from pydantic<2.11.0,>=2.10.3->unstructured-client->unstructured) (0.7.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (0.4.3)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.21)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic openpyxl\n",
    "!pip install pypdf\n",
    "!pip install -qU langchain-community langchain-openai\n",
    "!pip install pdf2image Pillow\n",
    "!pip install pdfplumber\n",
    "!pip install tqdm\n",
    "!pip install unstructured\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "552ad6f2-c369-4816-a5ff-9ba0614943af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: openpyxl in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (3.1.5)\nRequirement already satisfied: et-xmlfile in /local_disk0/.ephemeral_nfs/envs/pythonEnv-16a38afe-f127-4289-afcc-ac51b3a93ccc/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "import base64\n",
    "import requests\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl.utils import get_column_letter\n",
    "import openpyxl\n",
    "from matplotlib.table import Table\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69ca473a-ddfc-488e-aba5-3a34792b5052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Init SecureGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e100f867-ea01-40e9-8dc1-47294341f17b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class AuthConfig:\n",
    "    \"\"\"Configuration for authentication\"\"\"\n",
    "    base_url: str\n",
    "    client_id: str\n",
    "    client_secret: str\n",
    "    scope: str\n",
    "\n",
    "class AuthClient:\n",
    "    \"\"\"Client for handling authentication\"\"\"\n",
    "    def __init__(self, config: AuthConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_token(self) -> Dict[str, str]:\n",
    "        \"\"\"Get OAuth2 access token\"\"\"\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{self.config.base_url}/as/token.oauth2\",\n",
    "                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n",
    "                data={\n",
    "                    \"grant_type\": \"client_credentials\",\n",
    "                    \"client_id\": self.config.client_id,\n",
    "                    \"client_secret\": self.config.client_secret,\n",
    "                    \"scope\": self.config.scope\n",
    "                }\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise Exception(f\"Authentication failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4854ab60-4bbf-4b61-98f4-f92839e340f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_auth_token() -> str:\n",
    "    \"\"\"Helper function to get authentication token\"\"\"\n",
    "    config = AuthConfig(\n",
    "        base_url=\"https://onelogin.stg.axa.com\",\n",
    "        client_id=\"VJKkswZb\",\n",
    "        client_secret=\"yG3pl6nkYhvJlQVD1y7xbZBl692YRytdpUJeODKg5BAutoEgxhkqzXLFYGqH5zlp\",\n",
    "        scope=\"urn:grp:chatgpt\"\n",
    "    )\n",
    "    client = AuthClient(config)\n",
    "    result = client.get_token()\n",
    "    return result.get(\"access_token\", \"\")\n",
    "\n",
    "class SecureGPTChat:\n",
    "    \"\"\"Main class for interacting with SecureGPT API\"\"\"\n",
    "    def __init__(self, \n",
    "                token: str,\n",
    "                temperature: float = 0.05,\n",
    "                base_url: str = \"https://api-pp.se.axa-go.axa.com/ago-m365-securegpt-bapi-v1-vrs\",\n",
    "                model: str = \"gpt-4o-2024-08-06\"):\n",
    "        self.token = token\n",
    "        self.temperature = temperature\n",
    "        self.base_url = base_url\n",
    "        self.model = model\n",
    "        self.costs = {\n",
    "            'input_token': 2.50/1_000_000,\n",
    "            'output_token': 10.00/1_000_000,\n",
    "            'base_image_cost': 0.001913\n",
    "        }\n",
    "\n",
    "    def calculate_cost(self, response: Dict, image_path: Optional[str] = None) -> Dict[str, float]:\n",
    "        \"\"\"Calculate cost of API usage\"\"\"\n",
    "        total_cost = 0\n",
    "        metrics = {'token_cost': 0, 'image_cost': 0}\n",
    "\n",
    "        if 'usage' in response:\n",
    "            input_tokens = response['usage'].get('prompt_tokens', 0)\n",
    "            output_tokens = response['usage'].get('completion_tokens', 0)\n",
    "            metrics['token_cost'] = (input_tokens * self.costs['input_token'] + \n",
    "                                   output_tokens * self.costs['output_token'])\n",
    "            total_cost += metrics['token_cost']\n",
    "\n",
    "        if image_path:\n",
    "            try:\n",
    "                with Image.open(image_path) as img:\n",
    "                    width, height = img.size\n",
    "                    pixels = width * height\n",
    "                    metrics['image_cost'] = (pixels / (1024 * 1024)) * self.costs['base_image_cost']\n",
    "                    total_cost += metrics['image_cost']\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating image cost: {str(e)}\")\n",
    "\n",
    "        metrics['total_cost'] = total_cost\n",
    "        return metrics\n",
    "\n",
    "    def encode_image(self, image_path: str) -> str:\n",
    "        \"\"\"Encode image to base64\"\"\"\n",
    "        if image_path.startswith('data:image'):\n",
    "            return image_path.split('base64,')[1]\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    def prepare_messages(self, messages: List[Dict[str, Any]], \n",
    "                        image_path: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"Prepare messages for API request\"\"\"\n",
    "        formatted_messages = []\n",
    "        for msg in messages:\n",
    "            content = msg[\"content\"]\n",
    "            if image_path and msg == messages[-1]:\n",
    "                content = [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": f\"data:image/jpeg;base64,{self.encode_image(image_path)}\",\n",
    "                        \"detail\": \"auto\"\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": content}\n",
    "                ]\n",
    "            formatted_messages.append({\n",
    "                \"role\": msg.get(\"role\", \"user\"),\n",
    "                \"content\": content\n",
    "            })\n",
    "        return formatted_messages\n",
    "\n",
    "    def chat(self, messages: List[Dict[str, Any]], \n",
    "             image_path: Optional[str] = None, \n",
    "             **kwargs) -> Dict:\n",
    "        \"\"\"Send chat request to API\"\"\"\n",
    "        url = f\"{self.base_url}/deployments/{self.model}/chat/completions\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.token}\"\n",
    "        }\n",
    "        data = {\n",
    "            \"messages\": self.prepare_messages(messages, image_path),\n",
    "            \"temperature\": self.temperature,\n",
    "            \"max_tokens\": kwargs.get(\"max_tokens\", 12000)\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=data)\n",
    "            response.raise_for_status()\n",
    "            api_response = response.json()\n",
    "            cost_metrics = self.calculate_cost(api_response, image_path)\n",
    "            api_response['cost_metrics'] = cost_metrics\n",
    "            return api_response\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API Error Details: {response.text if 'response' in locals() else 'No response'}\")\n",
    "            raise Exception(f\"API call failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df0393f9-8eb9-433b-9f67-d8cba015840e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:447)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1315)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:1032)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:74)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:993)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:808)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:834)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:833)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:888)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:681)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:447)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1315)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:1032)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:74)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:993)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:808)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:834)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:833)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:888)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:681)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_chat_interface():\n",
    "    \"\"\"Create an interactive chat interface with the model\"\"\"\n",
    "    token = get_auth_token()\n",
    "    model = SecureGPTChat(\n",
    "        temperature=0.0,\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        token=token\n",
    "    )\n",
    "    history = []\n",
    "    \n",
    "    def chat_with_model():\n",
    "        while True:\n",
    "            user_input = input(\"\\nVous: \")\n",
    "            if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "                print(\"\\nAu revoir!\")\n",
    "                break\n",
    "                \n",
    "            # Add message to history\n",
    "            history.append({\"role\": \"user\", \"content\": user_input})\n",
    "            \n",
    "            # Get model response\n",
    "            try:\n",
    "                response = model.chat(history)\n",
    "                bot_response = response['choices'][0]['message']['content']\n",
    "                history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "                print(\"\\nAssistant:\", bot_response)\n",
    "            except Exception as e:\n",
    "                print(f\"\\nErreur: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    return chat_with_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70f1f2cb-baf9-4c30-8d09-adc96f38a0b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Transformation onglet excel (referentiel garantie) en json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ab02ba9-4d1a-4309-8b74-e7eb9130eea7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##onglet to image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b184139-e6e2-4c65-b735-34566097a954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ExcelStructureExtractor:\n",
    "    \"\"\"Class to handle Excel structure extraction and conversion to JSON\"\"\"\n",
    "    def __init__(self, excel_file: str):\n",
    "        self.excel_file = excel_file\n",
    "        self.workbook = None\n",
    "        \n",
    "    def initialize_workbook(self):\n",
    "        \"\"\"Initialize the Excel workbook\"\"\"\n",
    "        try:\n",
    "            self.workbook = openpyxl.load_workbook(self.excel_file)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Excel file: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def get_sheet_names(self) -> List[str]:\n",
    "        \"\"\"Get all sheet names from the workbook\"\"\"\n",
    "        if not self.workbook:\n",
    "            self.initialize_workbook()\n",
    "        return self.workbook.sheetnames\n",
    "    \n",
    "    def create_output_directories(self):\n",
    "        \"\"\"Create necessary output directories\"\"\"\n",
    "        Path('temp_images').mkdir(exist_ok=True)\n",
    "        Path('json_structures').mkdir(exist_ok=True)\n",
    "\n",
    "    def excel_sheet_to_image(self, sheet_name: str, output_path: str):\n",
    "        if not self.workbook:\n",
    "            self.initialize_workbook()\n",
    "            \n",
    "        ws = self.workbook[sheet_name]\n",
    "        \n",
    "        # Prtraitement du texte avec wrapping\n",
    "        data = []\n",
    "        for row in ws.rows:\n",
    "            processed_row = []\n",
    "            for cell in row:\n",
    "                text = str(cell.value) if cell.value is not None else ''\n",
    "                # Wrap le texte tous les 30 caractres\n",
    "                wrapped_text = '\\n'.join([text[i:i+30] for i in range(0, len(text), 30)])\n",
    "                processed_row.append(wrapped_text)\n",
    "            data.append(processed_row)\n",
    "        \n",
    "        # Calcul des hauteurs avec plus d'espace pour le texte\n",
    "        row_heights = []\n",
    "        for row in data:\n",
    "            max_lines = max(len(str(cell).split('\\n')) for cell in row)\n",
    "            row_heights.append(max_lines)\n",
    "        \n",
    "        # Calcul des largeurs avec contrainte\n",
    "        col_widths = [min(max(len(line) for cell in col for line in str(cell).split('\\n')), 30) \n",
    "                    for col in zip(*data)]\n",
    "        \n",
    "        # Dimensions ajustes\n",
    "        total_width = min(sum(col_widths) * 0.12, 40)\n",
    "        total_height = min(sum(row_heights) * 0.4, 30)  # Plus de hauteur pour le texte\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(total_width, total_height))\n",
    "        ax.axis('off')\n",
    "        \n",
    "        table = ax.table(\n",
    "            cellText=data,\n",
    "            cellLoc='left',\n",
    "            loc='center',\n",
    "            edges='BRTL'\n",
    "        )\n",
    "        \n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)  # Police rduite pour plus de texte\n",
    "        \n",
    "        # Ajustement des cellules avec plus d'espace vertical\n",
    "        for i, row in enumerate(data):\n",
    "            for j in range(len(row)):\n",
    "                cell = table[i, j]\n",
    "                cell.set_text_props(wrap=True, va='center')\n",
    "                cell._text.set_text(data[i][j])\n",
    "                \n",
    "                # Plus de hauteur pour les cellules avec beaucoup de texte\n",
    "                num_lines = len(str(data[i][j]).split('\\n'))\n",
    "                cell.set_height(max(num_lines * 0.03, 0.1))\n",
    "                cell.set_width(min(col_widths[j] * 0.015, 0.1))\n",
    "        \n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def excel_sheet_to_image2(self, sheet_name: str, output_path: str):\n",
    "        \"\"\"\n",
    "        Essaye de convertir un onglet Excel (feuille `sheet_name`) en image PNG,\n",
    "        en dimensionnant (approx.) le tableau  la quantit de texte.\n",
    "        \"\"\"\n",
    "        if not self.workbook:\n",
    "            self.initialize_workbook()\n",
    "        ws = self.workbook[sheet_name]\n",
    "\n",
    "        # -- Rcuprer le contenu cellulaire en mmoire --\n",
    "        data = []\n",
    "        for row in ws.rows:\n",
    "            row_values = []\n",
    "            for cell in row:\n",
    "                txt = str(cell.value) if cell.value is not None else \"\"\n",
    "                # On peut faire un lger wrapping manuel (tous les 30 caractres)\n",
    "                # si lon veut injecter des \\n\n",
    "                wrapped_txt = \"\\n\".join(txt[i:i+30] for i in range(0, len(txt), 30))\n",
    "                row_values.append(wrapped_txt)\n",
    "            data.append(row_values)\n",
    "\n",
    "        # Scurit si la feuille est vide\n",
    "        if not data:\n",
    "            print(f\"La feuille {sheet_name} est vide ou inexistante.\")\n",
    "            return\n",
    "\n",
    "        # Nombre de colonnes/rows effectifs\n",
    "        max_row = len(data)\n",
    "        max_col = max(len(r) for r in data)\n",
    "\n",
    "        # -- Calculer largeur / hauteur de chaque col/row en se basant sur la longueur de texte --\n",
    "        # On va estimer qu'un caractre prend ~0.12 pouce (trs approximatif)\n",
    "        # et qu'une ligne de texte prend ~0.2 pouce de hauteur.\n",
    "        width_per_char = 0.12\n",
    "        height_per_line = 0.2\n",
    "\n",
    "        # 1) Largeur de chaque colonne\n",
    "        col_widths = []\n",
    "        for col_idx in range(max_col):\n",
    "            max_len_in_col = 0\n",
    "            for row_idx in range(max_row):\n",
    "                if col_idx < len(data[row_idx]):\n",
    "                    cell_lines = data[row_idx][col_idx].split('\\n')\n",
    "                    # on regarde la ligne la plus longue\n",
    "                    longest_line = max(cell_lines, key=len) if cell_lines else \"\"\n",
    "                    max_len_in_col = max(max_len_in_col, len(longest_line))\n",
    "            # On se garde une marge +1\n",
    "            col_widths.append((max_len_in_col + 1) * width_per_char)\n",
    "\n",
    "        # 2) Hauteur de chaque ligne\n",
    "        row_heights = []\n",
    "        for row_idx in range(max_row):\n",
    "            # On regarde, dans chaque colonne, combien de lignes \\n on a\n",
    "            # et on prend le max\n",
    "            max_nb_lines = 1\n",
    "            for col_idx in range(len(data[row_idx])):\n",
    "                nb_lines = data[row_idx][col_idx].count('\\n') + 1\n",
    "                max_nb_lines = max(max_nb_lines, nb_lines)\n",
    "            row_heights.append(max_nb_lines * height_per_line)\n",
    "\n",
    "        # On obtient une taille totale du tableau\n",
    "        total_width = sum(col_widths)\n",
    "        total_height = sum(row_heights)\n",
    "\n",
    "        # On ajoute un peu de marge autour, par ex. 1 pouce\n",
    "        fig_margin = 1.0\n",
    "        fig, ax = plt.subplots(figsize=(total_width + fig_margin, total_height + fig_margin))\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        # -- Construction du tableau matplotlib --\n",
    "        table = Table(ax, bbox=[0, 0, 1, 1])\n",
    "        current_y = 0.0\n",
    "\n",
    "        for row_idx in range(max_row):\n",
    "            current_x = 0.0\n",
    "            for col_idx in range(max_col):\n",
    "                cell_txt = \"\"\n",
    "                if col_idx < len(data[row_idx]):\n",
    "                    cell_txt = data[row_idx][col_idx]\n",
    "\n",
    "                cw = col_widths[col_idx]\n",
    "                ch = row_heights[row_idx]\n",
    "\n",
    "                # Ajout d'une cellule\n",
    "                cell = table.add_cell(row=row_idx,\n",
    "                                    col=col_idx,\n",
    "                                    width=cw/(total_width),\n",
    "                                    height=ch/(total_height),\n",
    "                                    text=cell_txt,\n",
    "                                    loc='center',\n",
    "                                    edgecolor='black')\n",
    "\n",
    "                # On active le wrap\n",
    "                cell.set_text_props(wrap=True, va='center')\n",
    "            # Fin col\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "\n",
    "        table.rows = max_row\n",
    "        table.cols = max_col\n",
    "        ax.add_table(table)\n",
    "\n",
    "        # -- Sauvegarde de la figure --\n",
    "        plt.savefig(output_path, dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Image enregistre dans : {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d52e5a99-9fda-4750-b678-3f776ca577c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Image ton Json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4db74fa0-56a2-49f0-99b4-3f141571703e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_structure_with_securegpt(model: SecureGPTChat, \n",
    "                                  image_path: str, \n",
    "                                  example_json: Dict) -> Dict:\n",
    "   messages = [\n",
    "       {\n",
    "           \"role\": \"system\",\n",
    "           \"content\": f\"\"\"Tu es un expert en assurance analysant des tableaux Excel de paramtres d'endoso.\n",
    "\n",
    "Structure requise:\n",
    "0. S'il y a pas de colonne enfin si tu vois qu'il y a comme colonne standard parameters ce n'est pas une colonne mais c'est juste pour dire que les variables  ct et en dessous sont de type \"std\" donc quand il n'y a pas de colonne tu mets juste column_parameters : '' en gros un vide. S'il y a quelque chose qui ressemble  une garantie l tu mets sinon rien et surtout tu ne mets pas standard parameters...\n",
    "1. Les paramtres sous \"Standard Parameters\" doivent avoir type=\"std\"\n",
    "1bis. Les paramtres sous \"Parameters in exception\" doivent avoir type=\"exception\"\n",
    "1ter. Idem pour les options il peut y avoir d'autres cas que tu verras forcment sur l'image en dessous de standard, exception etc..\n",
    "2. Les paramtres doivent tre regroups par \"column_parameters\" si des colonnes sont visibles\n",
    "3. Si pas de colonnes visibles, utiliser uniquement \"raw_parameters\"  remplir et column_parameters : \"\"\n",
    "\n",
    "Voici un exemple de la structure attendue:\n",
    "{json.dumps(example_json, indent=2)}\n",
    "\n",
    "Points importants:\n",
    "- Crer les column_parameters uniquement si des colonnes sont visibles dans le tableau\n",
    "- Standard/Exception dfinissent uniquement le type du paramtre, pas la structure, il n'apparaissent pas dans la structure\n",
    "- Garder la mme structure que l'exemple fourni\n",
    "- Respecter les noms exacts des champs prsents dans l'exemple\n",
    "- Copier les valeurs textuelles exactes du tableau : TRES IMPORTANT C'EST A DIRE MEME S'IL Y A UN TEXTE LONG AVEC PLUSIEURS PHRASES DANS UNE CELLULE TU NE METS PAS QUE \"TEXT\" TU RECOPIES TOUT LE TEXTE.\n",
    "\n",
    "Retourne uniquement le JSON.\"\"\"\n",
    "       },\n",
    "       {\n",
    "           \"role\": \"user\", \n",
    "           \"content\": \"Extrais la structure JSON en respectant les rgles prdfinies.\"\n",
    "       }\n",
    "   ]\n",
    "   \n",
    "   response = model.chat(messages, image_path=image_path)\n",
    "   return json.loads(response['choices'][0]['message']['content'].strip().replace('```json', '').replace('```', ''))\n",
    "\n",
    "\n",
    "def extract_excel_to_text(excel_file, sheet_name):\n",
    "   import pandas as pd\n",
    "   df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "   text_content = df.to_string(index=False)\n",
    "   with open('paste.txt', 'w', encoding='utf-8') as f:\n",
    "       f.write(text_content)\n",
    "   return text_content\n",
    "\n",
    "def transform_table_with_llm():\n",
    "   # Charger l'exemple\n",
    "   with open('output_referential_example.json', 'r') as f:\n",
    "       example_json = json.load(f)\n",
    "       \n",
    "   # Lire le contenu \n",
    "   with open('paste.txt', 'r') as f:\n",
    "       table_content = f.read()\n",
    "\n",
    "   messages = [\n",
    "       {\n",
    "           \"role\": \"system\",\n",
    "           \"content\": f\"\"\"Tu es un expert en transformation de tableaux Excel en JSON. Ta tche est de transformer ce tableau en JSON en suivant EXACTEMENT la structure de l'exemple fourni.\n",
    "\n",
    "Voici l'exemple de structure  suivre:\n",
    "{json.dumps(example_json, indent=2)}\n",
    "\n",
    "Points cls:\n",
    "- Suit EXACTEMENT la mme structure que l'exemple\n",
    "- Les paramtres sous \"Standard Parameters\" ont type=\"std\"\n",
    "- Les paramtres sous \"Parameters in exception\" ont type=\"exception\"\n",
    "- Conserve TOUS les paramtres avec leurs value_type exacts\n",
    "- Inclut editable:true, active:true pour tous les paramtres\n",
    "- Extrait toutes les colonnes et sous-colonnes visibles\n",
    "- Chaque colonne principale (Cesarea, Parto Normal) devient un column_parameter_name\n",
    "- Les sous-sections (Pago directo, Reembolso) deviennent des column_parameter_details\n",
    "- Les paramtres deviennent des row_parameters\n",
    "- Tu mettras les valeurs textuelles exactes du tableau pour condition generale dans \"description\" par exemple\n",
    "\n",
    "Retourne uniquement le JSON, sans texte explicatif.\"\"\"\n",
    "       },\n",
    "       {\n",
    "           \"role\": \"user\",\n",
    "           \"content\": f\"Transforme ce tableau en JSON:\\n{table_content}\"\n",
    "       }\n",
    "   ]\n",
    "\n",
    "   model = SecureGPTChat(\n",
    "       temperature=0,\n",
    "       model=\"gpt-4o-2024-08-06\", \n",
    "       token=get_auth_token()\n",
    "   )\n",
    "\n",
    "   response = model.chat(messages)\n",
    "   return json.loads(response['choices'][0]['message']['content'].strip().replace('```json', '').replace('```', ''))\n",
    "\n",
    "# Utilisation\n",
    "text = extract_excel_to_text('input_referentials.xlsx', 'endoso_65')\n",
    "json_output = transform_table_with_llm()\n",
    "\n",
    "with open('output.json', 'w', encoding='utf-8') as f:\n",
    "   json.dump(json_output, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ea9c9a5-5b67-4159-9f6f-055f0ce2d411",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_excel_structure(excel_file: str, model: SecureGPTChat):\n",
    "    special_endosos = ['toto']  # Liste des endosos  traiter diffremment\n",
    "    \n",
    "    extractor = ExcelStructureExtractor(excel_file)\n",
    "    extractor.create_output_directories()\n",
    "    sheet_names = extractor.get_sheet_names()\n",
    "    \n",
    "    with open('output_referential_example.json', 'r') as f:\n",
    "        example_json = json.load(f)\n",
    "    \n",
    "    for sheet_name in tqdm(sheet_names, desc=\"Processing sheets\"):\n",
    "        if 'endoso' not in sheet_name.lower():\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing sheet: {sheet_name}\")\n",
    "        try:\n",
    "            if sheet_name not in special_endosos:\n",
    "                # Mthode alternative pour les endosos spciaux\n",
    "                text = extract_excel_to_text(excel_file, sheet_name)\n",
    "                structure = transform_table_with_llm()\n",
    "            else:\n",
    "                # Mthode standard\n",
    "                image_path = f\"temp_images/{sheet_name}.png\"\n",
    "                extractor.excel_sheet_to_image(sheet_name, image_path)\n",
    "                structure = extract_structure_with_securegpt(model, image_path, example_json)\n",
    "            \n",
    "            # Sauvegarde\n",
    "            json_path = f\"json_structures/{sheet_name}.json\"\n",
    "            with open(json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(structure, f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sheet {sheet_name}: {str(e)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "414a8799-afd9-4d00-a9c5-da072da66879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Brouillon test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f01c97cd-3cda-461f-9524-e2a2f8453932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = SecureGPTChat(\n",
    "   temperature=0.0,\n",
    "   model=\"gpt-4o-2024-08-06\",\n",
    "   token=get_auth_token()\n",
    ")\n",
    "numero = \"122\"\n",
    "extractor = ExcelStructureExtractor('input_referentials.xlsx')\n",
    "extractor.excel_sheet_to_image2(f\"endoso_{numero}\", f\"temp_images/endoso_{numero}.png\")\n",
    "\n",
    "\n",
    "with open('output_referential_example.json', 'r') as f:\n",
    "            example_json = json.load(f)\n",
    "image_path = f\"temp_images/endoso_{numero}.png\"\n",
    "model = SecureGPTChat(\n",
    "   temperature=0.0,\n",
    "   model=\"gpt-4o-2024-08-06\",\n",
    "   token=get_auth_token()\n",
    ")\n",
    "extract_structure_with_securegpt(model,image_path,example_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b755604c-2bbc-4e64-8efd-8dd1a6c34980",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8807bec8-40ac-498b-a81a-c1b921de40e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00 - Mexique Referentiel",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}